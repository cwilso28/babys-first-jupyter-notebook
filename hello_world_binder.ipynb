{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed93aa7",
   "metadata": {},
   "source": [
    "# Crawling\n",
    "The two following print statements are just to add content to this notebook so something can be uploaded to Github and then reuploaded. I wanted to see how the web interface handles pushes from my machine. Hint: Refresh the page following a push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c43461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print('Hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d154f4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a git commit test.\n"
     ]
    }
   ],
   "source": [
    "print('This is a git commit test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f163b7d",
   "metadata": {},
   "source": [
    "# Standing\n",
    "This section is to document the cleaning steps for the data files in the dataset folder. This duplicates my cleaning steps I performed in Excel for the Coursera Case Study 1. The report and processed dataset for that study can be found on my [Kaggle site](https://www.kaggle.com/code/scwilso28/coursera-case-study-1-cyclistic-data-analysis). A sample of the data has been uploaded here as a zip file to reduce file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c691f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb58f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('Datasets/202103-divvy-tripdata.zip')\n",
    "df = pd.read_csv(zf.open('202103-divvy-tripdata.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc396f93",
   "metadata": {},
   "source": [
    "## Memory usage\n",
    "Following the data import and loading into a dataframe, the dataframe structure is reviewed. My goal of this next section is to reduce the dataframe size, as it was consuming 146.0 MB. This data and it's size on it's own isn't an issue, but I will be performing the cleanup on all of the data files (13 files) associated with the case study and this dataset is one of the smaller sets. By the way, the info method for data frames is very useful, here's the [manual](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddc8dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228496 entries, 0 to 228495\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   ride_id             228496 non-null  object \n",
      " 1   rideable_type       228496 non-null  object \n",
      " 2   started_at          228496 non-null  object \n",
      " 3   ended_at            228496 non-null  object \n",
      " 4   start_station_name  213648 non-null  object \n",
      " 5   start_station_id    213648 non-null  object \n",
      " 6   end_station_name    211769 non-null  object \n",
      " 7   end_station_id      211769 non-null  object \n",
      " 8   start_lat           228496 non-null  float64\n",
      " 9   start_lng           228496 non-null  float64\n",
      " 10  end_lat             228329 non-null  float64\n",
      " 11  end_lng             228329 non-null  float64\n",
      " 12  member_casual       228496 non-null  object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 146.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95186da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['start_station_id', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng']\n",
    "df.drop(to_drop, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ee5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0e8cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228496 entries, 0 to 228495\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   ride_id             228496 non-null  object        \n",
      " 1   rideable_type       228496 non-null  object        \n",
      " 2   started_at          228496 non-null  datetime64[ns]\n",
      " 3   ended_at            228496 non-null  datetime64[ns]\n",
      " 4   start_station_name  213648 non-null  object        \n",
      " 5   end_station_name    211769 non-null  object        \n",
      " 6   member_casual       228496 non-null  int64         \n",
      "dtypes: datetime64[ns](2), int64(1), object(4)\n",
      "memory usage: 69.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFA86D4455AA1030</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-16 08:32:30</td>\n",
       "      <td>2021-03-16 08:36:34</td>\n",
       "      <td>Humboldt Blvd &amp; Armitage Ave</td>\n",
       "      <td>Stave St &amp; Armitage Ave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30D9DC61227D1AF3</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-28 01:26:28</td>\n",
       "      <td>2021-03-28 01:36:55</td>\n",
       "      <td>Humboldt Blvd &amp; Armitage Ave</td>\n",
       "      <td>Central Park Ave &amp; Bloomingdale Ave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>846D87A15682A284</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-11 21:17:29</td>\n",
       "      <td>2021-03-11 21:33:53</td>\n",
       "      <td>Shields Ave &amp; 28th Pl</td>\n",
       "      <td>Halsted St &amp; 35th St</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>994D05AA75A168F2</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-11 13:26:42</td>\n",
       "      <td>2021-03-11 13:55:41</td>\n",
       "      <td>Winthrop Ave &amp; Lawrence Ave</td>\n",
       "      <td>Broadway &amp; Sheridan Rd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF7464FBE92D8308</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-21 09:09:37</td>\n",
       "      <td>2021-03-21 09:27:33</td>\n",
       "      <td>Glenwood Ave &amp; Touhy Ave</td>\n",
       "      <td>Chicago Ave &amp; Sheridan Rd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id rideable_type          started_at            ended_at  \\\n",
       "0  CFA86D4455AA1030  classic_bike 2021-03-16 08:32:30 2021-03-16 08:36:34   \n",
       "1  30D9DC61227D1AF3  classic_bike 2021-03-28 01:26:28 2021-03-28 01:36:55   \n",
       "2  846D87A15682A284  classic_bike 2021-03-11 21:17:29 2021-03-11 21:33:53   \n",
       "3  994D05AA75A168F2  classic_bike 2021-03-11 13:26:42 2021-03-11 13:55:41   \n",
       "4  DF7464FBE92D8308  classic_bike 2021-03-21 09:09:37 2021-03-21 09:27:33   \n",
       "\n",
       "             start_station_name                     end_station_name  \\\n",
       "0  Humboldt Blvd & Armitage Ave              Stave St & Armitage Ave   \n",
       "1  Humboldt Blvd & Armitage Ave  Central Park Ave & Bloomingdale Ave   \n",
       "2         Shields Ave & 28th Pl                 Halsted St & 35th St   \n",
       "3   Winthrop Ave & Lawrence Ave               Broadway & Sheridan Rd   \n",
       "4      Glenwood Ave & Touhy Ave            Chicago Ave & Sheridan Rd   \n",
       "\n",
       "   member_casual  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['member_casual'] = df['member_casual'].map({'casual':0, 'member':1})\n",
    "df.info(memory_usage=\"deep\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1baff",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "I had performed this study using Excel, so I have some knowledge of issues that plague this data. Specifically, there are duplicates and invalid ride durations. \n",
    "\n",
    "The duplicates are a little sneaky. When this data was generated, any personal information was removed and replaced with a unique ride_id value. Unfortunately, that means if one user somehow made multiple copies of one ride, it would register as two different ride_id's with equal information for the remaining columns. The approach to get around the unique ride_id is to check for duplicates across the rest of the columns. Without input from the bike share company or stakeholders, I decided to delete the duplicates and report the number deleted for documentation. I wouldn't advise doing this without additional input.\n",
    "\n",
    "There are a few instances where the ended_at datetime is before the started_at datetime. I don't know how this happened, so again in isolation, the decision was made to just zero out the negative time deltas calculated to make this exercise work. Again, I don't recommend doing this right away. At least talk to someone before overriding values. Maybe the rider was a time traveler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1724ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "duplicate_check = ['rideable_type', 'started_at', 'ended_at', 'start_station_name', 'end_station_name', 'member_casual']\n",
    "duplicate_entries = df[df.duplicated(subset = duplicate_check, keep = False)]\n",
    "duplicate_list_length = len(duplicate_entries.drop_duplicates(subset=duplicate_check))\n",
    "print(duplicate_list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e018e149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011378754989146419\n"
     ]
    }
   ],
   "source": [
    "print(100*duplicate_list_length/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ef7d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228496\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87d6f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228470\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(subset = duplicate_check, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc7d3b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>ride_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-16 08:32:30</td>\n",
       "      <td>2021-03-16 08:36:34</td>\n",
       "      <td>0 days 00:04:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-28 01:26:28</td>\n",
       "      <td>2021-03-28 01:36:55</td>\n",
       "      <td>0 days 00:10:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-11 21:17:29</td>\n",
       "      <td>2021-03-11 21:33:53</td>\n",
       "      <td>0 days 00:16:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-11 13:26:42</td>\n",
       "      <td>2021-03-11 13:55:41</td>\n",
       "      <td>0 days 00:28:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-21 09:09:37</td>\n",
       "      <td>2021-03-21 09:27:33</td>\n",
       "      <td>0 days 00:17:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           started_at            ended_at   ride_duration\n",
       "0 2021-03-16 08:32:30 2021-03-16 08:36:34 0 days 00:04:04\n",
       "1 2021-03-28 01:26:28 2021-03-28 01:36:55 0 days 00:10:27\n",
       "2 2021-03-11 21:17:29 2021-03-11 21:33:53 0 days 00:16:24\n",
       "3 2021-03-11 13:26:42 2021-03-11 13:55:41 0 days 00:28:59\n",
       "4 2021-03-21 09:09:37 2021-03-21 09:27:33 0 days 00:17:56"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ride_duration'] = df.ended_at - df.started_at\n",
    "df[['started_at', 'ended_at', 'ride_duration']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3255e79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 days +23:59:59\n"
     ]
    }
   ],
   "source": [
    "print(df.ride_duration.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b4dc477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "zero_timedelta = pd.to_timedelta(0)\n",
    "column = df['ride_duration']\n",
    "print(column[column < zero_timedelta].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d8a4e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df['ride_duration'].values[df['ride_duration'].values < zero_timedelta] = zero_timedelta\n",
    "print(column[column < zero_timedelta].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32970495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>ride_duration</th>\n",
       "      <th>ride_duration_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFA86D4455AA1030</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-16 08:32:30</td>\n",
       "      <td>2021-03-16 08:36:34</td>\n",
       "      <td>Humboldt Blvd &amp; Armitage Ave</td>\n",
       "      <td>Stave St &amp; Armitage Ave</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:04:04</td>\n",
       "      <td>0.067778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30D9DC61227D1AF3</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-28 01:26:28</td>\n",
       "      <td>2021-03-28 01:36:55</td>\n",
       "      <td>Humboldt Blvd &amp; Armitage Ave</td>\n",
       "      <td>Central Park Ave &amp; Bloomingdale Ave</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:10:27</td>\n",
       "      <td>0.174167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>846D87A15682A284</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-11 21:17:29</td>\n",
       "      <td>2021-03-11 21:33:53</td>\n",
       "      <td>Shields Ave &amp; 28th Pl</td>\n",
       "      <td>Halsted St &amp; 35th St</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:16:24</td>\n",
       "      <td>0.273333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>994D05AA75A168F2</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-11 13:26:42</td>\n",
       "      <td>2021-03-11 13:55:41</td>\n",
       "      <td>Winthrop Ave &amp; Lawrence Ave</td>\n",
       "      <td>Broadway &amp; Sheridan Rd</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:28:59</td>\n",
       "      <td>0.483056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF7464FBE92D8308</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-03-21 09:09:37</td>\n",
       "      <td>2021-03-21 09:27:33</td>\n",
       "      <td>Glenwood Ave &amp; Touhy Ave</td>\n",
       "      <td>Chicago Ave &amp; Sheridan Rd</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:17:56</td>\n",
       "      <td>0.298889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id rideable_type          started_at            ended_at  \\\n",
       "0  CFA86D4455AA1030  classic_bike 2021-03-16 08:32:30 2021-03-16 08:36:34   \n",
       "1  30D9DC61227D1AF3  classic_bike 2021-03-28 01:26:28 2021-03-28 01:36:55   \n",
       "2  846D87A15682A284  classic_bike 2021-03-11 21:17:29 2021-03-11 21:33:53   \n",
       "3  994D05AA75A168F2  classic_bike 2021-03-11 13:26:42 2021-03-11 13:55:41   \n",
       "4  DF7464FBE92D8308  classic_bike 2021-03-21 09:09:37 2021-03-21 09:27:33   \n",
       "\n",
       "             start_station_name                     end_station_name  \\\n",
       "0  Humboldt Blvd & Armitage Ave              Stave St & Armitage Ave   \n",
       "1  Humboldt Blvd & Armitage Ave  Central Park Ave & Bloomingdale Ave   \n",
       "2         Shields Ave & 28th Pl                 Halsted St & 35th St   \n",
       "3   Winthrop Ave & Lawrence Ave               Broadway & Sheridan Rd   \n",
       "4      Glenwood Ave & Touhy Ave            Chicago Ave & Sheridan Rd   \n",
       "\n",
       "   member_casual   ride_duration  ride_duration_hrs  \n",
       "0              0 0 days 00:04:04           0.067778  \n",
       "1              0 0 days 00:10:27           0.174167  \n",
       "2              0 0 days 00:16:24           0.273333  \n",
       "3              0 0 days 00:28:59           0.483056  \n",
       "4              0 0 days 00:17:56           0.298889  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ride_duration_hrs'] = df.ride_duration / np.timedelta64(1, 'h')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5b7d4",
   "metadata": {},
   "source": [
    "# Conclusions and Final Thoughts\n",
    "The Excel duplicate removal tool removed 27 duplicates, but it did not include the member_casual column in the helper column that the duplicate check list is emulating. The steps taken here show that one entry was removed in error in the Excel data cleaning. The number of duplicates in this file is low, at 0.011%, so I would consider the differences in clean up tools as negligible. \n",
    "\n",
    "The number of negative ride durations was not recorded, but the amount here is also negligible, relative to the total number of entries (0.0009%). While it's not recommended to just replace data values, I'm it for the exercise.\n",
    "\n",
    "This was a good exercise in cleaning data using pandas, with my Excel process as a guiding hand. Now time to clean the rest of the data and analyze it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa9ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
